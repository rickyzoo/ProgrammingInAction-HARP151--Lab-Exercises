{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3ba92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de59366",
   "metadata": {},
   "source": [
    "I used the Open Trivia DB API provided in March 14's lecture slides. I was absent for this lecture and it doesn't seem like we actually worked with this API throughout any point in the API lectures so I hope it's okay that I used it for this lab. I did not include a response for the last part of the lab (explaining a larger project to complete with this API) because we were provided with a Github repository containing a comprehensive Trivia game utilizing the data from this API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0ff6d",
   "metadata": {},
   "source": [
    "### Use at least 5 unique API calls from the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa387be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_code': 0,\n",
       " 'results': [{'category': 'General Knowledge',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'On a dartboard, what number is directly opposite No. 1?',\n",
       "   'correct_answer': '19',\n",
       "   'incorrect_answers': ['20', '12', '15']},\n",
       "  {'category': 'Entertainment: Film',\n",
       "   'type': 'boolean',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'The word &quot;Inception&quot; came from the 2010 blockbuster hit &quot;Inception&quot;.',\n",
       "   'correct_answer': 'False',\n",
       "   'incorrect_answers': ['True']},\n",
       "  {'category': 'Politics',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'medium',\n",
       "   'question': 'The 2014 movie &quot;The Raid 2: Berandal&quot; was mainly filmed in which Asian country?',\n",
       "   'correct_answer': 'Indonesia',\n",
       "   'incorrect_answers': ['Thailand', 'Brunei', 'Malaysia']},\n",
       "  {'category': 'Entertainment: Japanese Anime & Manga',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'hard',\n",
       "   'question': 'What year was &quot;JoJo&#039;s Bizarre Adventure: Phantom Blood&quot; first released?',\n",
       "   'correct_answer': '1987',\n",
       "   'incorrect_answers': ['2013', '1983', '1995']},\n",
       "  {'category': 'History',\n",
       "   'type': 'boolean',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'Former United States Presidents John Adams and Thomas Jefferson died within hours of each other.',\n",
       "   'correct_answer': 'True',\n",
       "   'incorrect_answers': ['False']},\n",
       "  {'category': 'Entertainment: Video Games',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'medium',\n",
       "   'question': 'What name does the little headcrab in &quot;Half Life 2&quot; have?',\n",
       "   'correct_answer': 'Lamarr',\n",
       "   'incorrect_answers': ['Jumperr', 'Drett', 'Jerry']},\n",
       "  {'category': 'History',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'hard',\n",
       "   'question': 'When did Lithuania declare independence from the Soviet Union?',\n",
       "   'correct_answer': 'March 11th, 1990',\n",
       "   'incorrect_answers': ['December 25th, 1991',\n",
       "    'December 5th, 1991',\n",
       "    'April 20th, 1989']},\n",
       "  {'category': 'Science: Mathematics',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'hard',\n",
       "   'question': 'What is the plane curve proposed by Descartes to challenge Fermat&#039;s extremum-finding techniques called?',\n",
       "   'correct_answer': 'Folium of Descartes',\n",
       "   'incorrect_answers': ['Elliptic Paraboloid of Descartes',\n",
       "    'Cartesian Coordinates',\n",
       "    'Descarte&#039;s Helicoid']},\n",
       "  {'category': 'Science & Nature',\n",
       "   'type': 'boolean',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'Water always boils at 100&deg;C, 212&deg;F, 373.15K, no matter where you are.',\n",
       "   'correct_answer': 'False',\n",
       "   'incorrect_answers': ['True']},\n",
       "  {'category': 'History',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'medium',\n",
       "   'question': 'Which Roman Emperor led the Roman Empire to reach its maximum territorial extent?',\n",
       "   'correct_answer': 'Trajan',\n",
       "   'incorrect_answers': ['Julius Caesar',\n",
       "    'Claudius',\n",
       "    'Constantine the Great']}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default Trivia API url (call 1)\n",
    "\n",
    "url = \"https://opentdb.com/api.php?amount=10\"\n",
    "\n",
    "trivia_data = requests.get(url)\n",
    "json = trivia_data.json()\n",
    "\n",
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786535d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trivia_categories': [{'id': 9, 'name': 'General Knowledge'},\n",
       "  {'id': 10, 'name': 'Entertainment: Books'},\n",
       "  {'id': 11, 'name': 'Entertainment: Film'},\n",
       "  {'id': 12, 'name': 'Entertainment: Music'},\n",
       "  {'id': 13, 'name': 'Entertainment: Musicals & Theatres'},\n",
       "  {'id': 14, 'name': 'Entertainment: Television'},\n",
       "  {'id': 15, 'name': 'Entertainment: Video Games'},\n",
       "  {'id': 16, 'name': 'Entertainment: Board Games'},\n",
       "  {'id': 17, 'name': 'Science & Nature'},\n",
       "  {'id': 18, 'name': 'Science: Computers'},\n",
       "  {'id': 19, 'name': 'Science: Mathematics'},\n",
       "  {'id': 20, 'name': 'Mythology'},\n",
       "  {'id': 21, 'name': 'Sports'},\n",
       "  {'id': 22, 'name': 'Geography'},\n",
       "  {'id': 23, 'name': 'History'},\n",
       "  {'id': 24, 'name': 'Politics'},\n",
       "  {'id': 25, 'name': 'Art'},\n",
       "  {'id': 26, 'name': 'Celebrities'},\n",
       "  {'id': 27, 'name': 'Animals'},\n",
       "  {'id': 28, 'name': 'Vehicles'},\n",
       "  {'id': 29, 'name': 'Entertainment: Comics'},\n",
       "  {'id': 30, 'name': 'Science: Gadgets'},\n",
       "  {'id': 31, 'name': 'Entertainment: Japanese Anime & Manga'},\n",
       "  {'id': 32, 'name': 'Entertainment: Cartoon & Animations'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category lookup (call 2)\n",
    "\n",
    "url1 = \"https://opentdb.com/api_category.php\"\n",
    "\n",
    "category_data = requests.get(url1)\n",
    "json1 = category_data.json()\n",
    "\n",
    "json1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5523394d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category_id': 10,\n",
       " 'category_question_count': {'total_question_count': 97,\n",
       "  'total_easy_question_count': 30,\n",
       "  'total_medium_question_count': 41,\n",
       "  'total_hard_question_count': 26}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category Question Count lookup for \"Entertainment: Books\" (call 3)\n",
    "\n",
    "url2 = \"https://opentdb.com/api_count.php?category=10\"\n",
    "\n",
    "books_data = requests.get(url2)\n",
    "json2 = books_data.json()\n",
    "\n",
    "json2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcfb48bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': {'total_num_of_questions': 17497,\n",
       "  'total_num_of_pending_questions': 9042,\n",
       "  'total_num_of_verified_questions': 4098,\n",
       "  'total_num_of_rejected_questions': 4358},\n",
       " 'categories': {'9': {'total_num_of_questions': 4017,\n",
       "   'total_num_of_pending_questions': 1908,\n",
       "   'total_num_of_verified_questions': 305,\n",
       "   'total_num_of_rejected_questions': 1804},\n",
       "  '10': {'total_num_of_questions': 441,\n",
       "   'total_num_of_pending_questions': 257,\n",
       "   'total_num_of_verified_questions': 97,\n",
       "   'total_num_of_rejected_questions': 87},\n",
       "  '11': {'total_num_of_questions': 1017,\n",
       "   'total_num_of_pending_questions': 654,\n",
       "   'total_num_of_verified_questions': 247,\n",
       "   'total_num_of_rejected_questions': 116},\n",
       "  '12': {'total_num_of_questions': 1080,\n",
       "   'total_num_of_pending_questions': 567,\n",
       "   'total_num_of_verified_questions': 364,\n",
       "   'total_num_of_rejected_questions': 149},\n",
       "  '13': {'total_num_of_questions': 122,\n",
       "   'total_num_of_pending_questions': 74,\n",
       "   'total_num_of_verified_questions': 31,\n",
       "   'total_num_of_rejected_questions': 17},\n",
       "  '14': {'total_num_of_questions': 658,\n",
       "   'total_num_of_pending_questions': 396,\n",
       "   'total_num_of_verified_questions': 170,\n",
       "   'total_num_of_rejected_questions': 92},\n",
       "  '15': {'total_num_of_questions': 3458,\n",
       "   'total_num_of_pending_questions': 1796,\n",
       "   'total_num_of_verified_questions': 960,\n",
       "   'total_num_of_rejected_questions': 702},\n",
       "  '16': {'total_num_of_questions': 213,\n",
       "   'total_num_of_pending_questions': 118,\n",
       "   'total_num_of_verified_questions': 59,\n",
       "   'total_num_of_rejected_questions': 36},\n",
       "  '17': {'total_num_of_questions': 763,\n",
       "   'total_num_of_pending_questions': 404,\n",
       "   'total_num_of_verified_questions': 229,\n",
       "   'total_num_of_rejected_questions': 130},\n",
       "  '18': {'total_num_of_questions': 651,\n",
       "   'total_num_of_pending_questions': 283,\n",
       "   'total_num_of_verified_questions': 159,\n",
       "   'total_num_of_rejected_questions': 209},\n",
       "  '19': {'total_num_of_questions': 316,\n",
       "   'total_num_of_pending_questions': 122,\n",
       "   'total_num_of_verified_questions': 53,\n",
       "   'total_num_of_rejected_questions': 141},\n",
       "  '20': {'total_num_of_questions': 162,\n",
       "   'total_num_of_pending_questions': 85,\n",
       "   'total_num_of_verified_questions': 57,\n",
       "   'total_num_of_rejected_questions': 20},\n",
       "  '21': {'total_num_of_questions': 703,\n",
       "   'total_num_of_pending_questions': 432,\n",
       "   'total_num_of_verified_questions': 132,\n",
       "   'total_num_of_rejected_questions': 139},\n",
       "  '22': {'total_num_of_questions': 698,\n",
       "   'total_num_of_pending_questions': 320,\n",
       "   'total_num_of_verified_questions': 275,\n",
       "   'total_num_of_rejected_questions': 103},\n",
       "  '23': {'total_num_of_questions': 846,\n",
       "   'total_num_of_pending_questions': 390,\n",
       "   'total_num_of_verified_questions': 310,\n",
       "   'total_num_of_rejected_questions': 147},\n",
       "  '24': {'total_num_of_questions': 230,\n",
       "   'total_num_of_pending_questions': 124,\n",
       "   'total_num_of_verified_questions': 59,\n",
       "   'total_num_of_rejected_questions': 47},\n",
       "  '25': {'total_num_of_questions': 159,\n",
       "   'total_num_of_pending_questions': 100,\n",
       "   'total_num_of_verified_questions': 29,\n",
       "   'total_num_of_rejected_questions': 30},\n",
       "  '26': {'total_num_of_questions': 225,\n",
       "   'total_num_of_pending_questions': 131,\n",
       "   'total_num_of_verified_questions': 52,\n",
       "   'total_num_of_rejected_questions': 42},\n",
       "  '27': {'total_num_of_questions': 273,\n",
       "   'total_num_of_pending_questions': 159,\n",
       "   'total_num_of_verified_questions': 75,\n",
       "   'total_num_of_rejected_questions': 39},\n",
       "  '28': {'total_num_of_questions': 265,\n",
       "   'total_num_of_pending_questions': 143,\n",
       "   'total_num_of_verified_questions': 71,\n",
       "   'total_num_of_rejected_questions': 51},\n",
       "  '29': {'total_num_of_questions': 165,\n",
       "   'total_num_of_pending_questions': 59,\n",
       "   'total_num_of_verified_questions': 67,\n",
       "   'total_num_of_rejected_questions': 39},\n",
       "  '30': {'total_num_of_questions': 86,\n",
       "   'total_num_of_pending_questions': 45,\n",
       "   'total_num_of_verified_questions': 24,\n",
       "   'total_num_of_rejected_questions': 17},\n",
       "  '31': {'total_num_of_questions': 658,\n",
       "   'total_num_of_pending_questions': 312,\n",
       "   'total_num_of_verified_questions': 184,\n",
       "   'total_num_of_rejected_questions': 162},\n",
       "  '32': {'total_num_of_questions': 291,\n",
       "   'total_num_of_pending_questions': 163,\n",
       "   'total_num_of_verified_questions': 89,\n",
       "   'total_num_of_rejected_questions': 39}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Global Question Count lookup (call 4)\n",
    "\n",
    "url3 = \"https://opentdb.com/api_count_global.php\"\n",
    "\n",
    "globalques_data = requests.get(url3)\n",
    "json3 = globalques_data.json()\n",
    "\n",
    "json3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b41384c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response_code': 0,\n",
       " 'results': [{'category': 'Science%3A%20Computers',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'Which%20company%20was%20established%20on%20April%201st%2C%201976%20by%20Steve%20Jobs%2C%20Steve%20Wozniak%20and%20Ronald%20Wayne%3F',\n",
       "   'correct_answer': 'Apple',\n",
       "   'incorrect_answers': ['Microsoft', 'Atari', 'Commodore']},\n",
       "  {'category': 'History',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'Which%20of%20the%20following%20African%20countries%20was%20most%20successful%20in%20resisting%20colonization%3F',\n",
       "   'correct_answer': 'Ethiopia',\n",
       "   'incorrect_answers': ['C%C3%B4te%20d%E2%80%99Ivoire', 'Congo', 'Namibia']},\n",
       "  {'category': 'Entertainment%3A%20Japanese%20Anime%20%26%20Manga',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'What%20is%20the%20name%20of%20the%20stuffed%20lion%20in%20Bleach%3F',\n",
       "   'correct_answer': 'Kon',\n",
       "   'incorrect_answers': ['Jo', 'Urdiu', 'Chad']},\n",
       "  {'category': 'Science%3A%20Computers',\n",
       "   'type': 'boolean',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'Ada%20Lovelace%20is%20often%20considered%20the%20first%20computer%20programmer.',\n",
       "   'correct_answer': 'True',\n",
       "   'incorrect_answers': ['False']},\n",
       "  {'category': 'Entertainment%3A%20Music',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'In%20Mean%20Girls%2C%20who%20has%20breasts%20that%20tell%20when%20it%27s%20raining%3F',\n",
       "   'correct_answer': 'Karen%20Smith',\n",
       "   'incorrect_answers': ['Gretchen%20Weiners',\n",
       "    'Janice%20Ian',\n",
       "    'Cady%20Heron']},\n",
       "  {'category': 'Vehicles',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'medium',\n",
       "   'question': 'Which%20one%20is%20NOT%20the%20function%20of%20engine%20oil%20in%20car%20engines%3F',\n",
       "   'correct_answer': 'Combustion',\n",
       "   'incorrect_answers': ['Lubrication', 'Cooling', 'Reduce%20corrosion']},\n",
       "  {'category': 'Entertainment%3A%20Television',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'The%20%22Psycho%22%20series%20of%20videos%20on%20YouTube%20was%20created%20by%20which%20of%20the%20following%3F',\n",
       "   'correct_answer': 'RiDGiD%20STUDiOS',\n",
       "   'incorrect_answers': ['Dan%20Bell', 'Billy%20Familia', 'VeganGainz']},\n",
       "  {'category': 'Entertainment%3A%20Music',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'medium',\n",
       "   'question': 'Which%20country%20does%20the%20power%20metal%20band%20%22Sabaton%22%20originate%20from%3F',\n",
       "   'correct_answer': 'Sweden',\n",
       "   'incorrect_answers': ['Germany', 'United%20States', 'Finland']},\n",
       "  {'category': 'Entertainment%3A%20Video%20Games',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'hard',\n",
       "   'question': 'What%20is%20the%20name%20of%20the%20main%20island%20in%20PLAYERUNKNOWN%27S%20BATTLEGROUNDS%3F',\n",
       "   'correct_answer': 'Erangel',\n",
       "   'incorrect_answers': ['Marmara', 'Severny', 'Lastovo']},\n",
       "  {'category': 'Entertainment%3A%20Television',\n",
       "   'type': 'multiple',\n",
       "   'difficulty': 'easy',\n",
       "   'question': 'What%20Nickelodeon%20game%20show%20featured%20a%20house%20on%20the%20set%20that%20the%20contestants%20would%20ransack%20to%20find%20hidden%20objects%3F',\n",
       "   'correct_answer': 'Finders%20Keepers',\n",
       "   'incorrect_answers': ['Double%20Dare',\n",
       "    'Nickelodeon%20Guts',\n",
       "    'Nick%20Arcade']}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizing URL Encoding (call 5)\n",
    "\n",
    "url4 = \"https://opentdb.com/api.php?amount=10&encode=url3986\"\n",
    "\n",
    "urlencode_data = requests.get(url4)\n",
    "json4 = urlencode_data.json()\n",
    "\n",
    "json4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e071d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b6edb1b",
   "metadata": {},
   "source": [
    "### Create a program that uses the API\n",
    "\n",
    "Here, I combine the information from call 2 and call 4 into one csv file that specifies the question count breakdown for each respective category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92e3b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ques_file = open(\"cat_ques.csv\", \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "csv_writer = csv.writer(cat_ques_file)\n",
    "csv_writer.writerow([\"Trivia_Category\", \"Total_Num_of_Questions\", \"Total_Num_of_Pending_Questions\",\n",
    "                    \"Total_Num_of_Verified_Questions\", \"Total_Num_of_Rejected_Questions\"])\n",
    "\n",
    "for i in range(len(json1['trivia_categories'])):\n",
    "    \n",
    "    cat = json1['trivia_categories'][i]['name']\n",
    "    total_quest = json3['categories'][str(i+9)][\"total_num_of_questions\"]\n",
    "    pend_quest = json3['categories'][str(i+9)][\"total_num_of_pending_questions\"]\n",
    "    veri_quest = json3['categories'][str(i+9)][\"total_num_of_verified_questions\"]\n",
    "    rej_quest = json3['categories'][str(i+9)][\"total_num_of_rejected_questions\"]\n",
    "    \n",
    "    csv_writer.writerow([cat, total_quest, pend_quest, veri_quest, rej_quest])\n",
    "    \n",
    "cat_ques_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e3a7539f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trivia_Category</th>\n",
       "      <th>Total_Num_of_Questions</th>\n",
       "      <th>Total_Num_of_Pending_Questions</th>\n",
       "      <th>Total_Num_of_Verified_Questions</th>\n",
       "      <th>Total_Num_of_Rejected_Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Knowledge</td>\n",
       "      <td>4017</td>\n",
       "      <td>1908</td>\n",
       "      <td>305</td>\n",
       "      <td>1804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entertainment: Books</td>\n",
       "      <td>441</td>\n",
       "      <td>257</td>\n",
       "      <td>97</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Entertainment: Film</td>\n",
       "      <td>1017</td>\n",
       "      <td>654</td>\n",
       "      <td>247</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entertainment: Music</td>\n",
       "      <td>1080</td>\n",
       "      <td>567</td>\n",
       "      <td>364</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entertainment: Musicals &amp; Theatres</td>\n",
       "      <td>122</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Trivia_Category  Total_Num_of_Questions  \\\n",
       "0                   General Knowledge                    4017   \n",
       "1                Entertainment: Books                     441   \n",
       "2                 Entertainment: Film                    1017   \n",
       "3                Entertainment: Music                    1080   \n",
       "4  Entertainment: Musicals & Theatres                     122   \n",
       "\n",
       "   Total_Num_of_Pending_Questions  Total_Num_of_Verified_Questions  \\\n",
       "0                            1908                              305   \n",
       "1                             257                               97   \n",
       "2                             654                              247   \n",
       "3                             567                              364   \n",
       "4                              74                               31   \n",
       "\n",
       "   Total_Num_of_Rejected_Questions  \n",
       "0                             1804  \n",
       "1                               87  \n",
       "2                              116  \n",
       "3                              149  \n",
       "4                               17  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"cat_ques.csv\")\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f8c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90aa9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9949ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
